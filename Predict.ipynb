{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict and Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os\n",
    "import argparse\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torchvision import transforms as T\n",
    "\n",
    "from ntm import NTM\n",
    "from task_generator import CopyDataset, AssociativeDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== Load the Task Configuration files ====\n",
    "# Copy Task ===\n",
    "task_params = json.load(open('configs/copy.json'))\n",
    "task_params['min_seq_len'] = 60\n",
    "task_params['max_seq_len'] = 120\n",
    "\n",
    "# Associative Recall Task ===\n",
    "# task_params['min_item'] = 6\n",
    "# task_params['max_item'] = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== Create Dataset ====\n",
    "dataset = CopyDataset(task_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== Create NTM ====\n",
    "ntm = NTM(input_dim=task_params['seq_width'] + 2,\n",
    "          output_dim=task_params['seq_width'],\n",
    "          ctrl_dim=task_params['controller_size'],\n",
    "          memory_units=task_params['memory_units'],\n",
    "          memory_unit_size=task_params['memory_unit_size'],\n",
    "          num_heads=task_params['num_heads'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load trained model weights\n",
    "ntm.load_state_dict(torch.load('model_copy.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 0.0 bits per sequence\n"
     ]
    }
   ],
   "source": [
    "# Reset\n",
    "ntm.reset()\n",
    "\n",
    "# Sample data\n",
    "data = dataset[np.random.randint(65536)]\n",
    "inputs, target = data['input'], data['target']\n",
    "\n",
    "# Tensor to store outputs\n",
    "out = torch.zeros(target.size())\n",
    "\n",
    "# Process the inputs through NTM for memorization\n",
    "for i in range(inputs.size()[0]):\n",
    "    # Forward passing all sequences for read\n",
    "    ntm(inputs[i].unsqueeze(0))\n",
    "\n",
    "# Get the outputs from memory without real inputs\n",
    "zero_inputs = torch.zeros(inputs.size()[1]).unsqueeze(0) # dummy inputs\n",
    "for i in range(target.size()[0]):\n",
    "    out[i] = ntm(zero_inputs)\n",
    "\n",
    "# Calculate binary outputs\n",
    "binary_output = out.clone()\n",
    "binary_output = binary_output.detach().apply_(lambda x: 0 if x < 0.5 else 1)\n",
    "\n",
    "# Sequence prediction error is calculted in bits per sequence\n",
    "error = torch.sum(torch.abs(binary_output - target))\n",
    "print(f'Error: {error} bits per sequence')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforms Compose object\n",
    "visualize = T.Compose([T.ToPILImage(), T.Resize(128, interpolation=0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA4AAAACACAAAAAB/t1gWAAADCElEQVR4nO3cO24bQRBAQdPw/a9sp2bQQmtmqZdURRLE4X7Ih01a8/q18vf/X167v4yvejMu+SEH57885fmaR/OdPVjymv4wr/8Zy5s5nvPy+3dw/8bjL8/y4Pvze3xn4OMECCEBQkiAEBIghAQIIQFCSIAQEiCEBAghAUJIgBD6c7BmOWU8DrPO6w+Gid+MhzmZ3319+1VHM9vj+tGjI9u749/On7/GX3Zuvz/zq3bHnN/49vP3BISQACEkQAgJEEIChJAAISRACAkQQgKEkAAhJEAICRBC78PYt8PEOweTzbfD0Afzxyc7W4/rT3ZWPrj+R+3e+XZn6Ed3Jj/4yA72DF8u2X3+noAQEiCEBAghAUJIgBASIIQECCEBQkiAEBIghAQIoS825v3YLOLt+pPB0O+/6noWcFxyO755e/4Hu+w+ujHvycmsjrL06Czp7srmz98TEEIChJAAISRACAkQQgKEkAAhJEAICRBCAoSQACEkQAh9MYz9v4OR5+th4CcVG9uODo5/O3+8tPtkDzamPdmYdzfMvHO7MfDtMPrMExBCAoSQACEkQAgJEEIChJAAISRACAkQQgKEkAAhJEAIvQ9jL8esL5cczG/P62+HqW9PZn6z1/DzF4e83cx752Cy/nPz67ffn58Zpl/e8vFi5rP0BISQACEkQAgJEEIChJAAISRACAkQQgKEkAAhJEAICRBC78PY45jr3/FVb3aTtZ+bLB4PU++sfLKz+PdftRwGfvT+H9hthr0cZj44/9svw6Pz356AEBIghAQIIQFCSIAQEiCEBAghAUJIgBASIIQECCEBQuiLwdJxGPZkMni3/tFh5nEY+9bBZPDJMPHB/Vsec7Qbxr+9/s9d8s6jn9+8fnf/PAEhJEAICRBCAoSQACEkQAgJEEIChJAAISRACAkQQq/bXUqBc56AEBIghAQIIQFCSIAQEiCEBAghAUJIgBASIIQECCEBQsj4Nfyst/9/8ASEkAAhJEAICRBCAoSQACEkQAgJEEIChJAAISRACAkQQv8AvJSKCKGC4EIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=896x128 at 0x24E15166278>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize Input\n",
    "visualize(inputs.permute(1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABEAAAACACAAAAAAuM0M0AAAC8klEQVR4nO3cQW7cMBAAwTjY/385ucsIiGmScg5VN0dLaldSGjrN16+FP4+/v4bHV/s9rdb/tN3fO/19q+u1srpfu+un+/9v9/f287t7vVb7P91+Pp+f/734PMA/CQiQCQiQCQiQCQiQCQiQCQiQCQiQCQiQCQiQCQiQCQiQCQiQCQiQCQiQfaYLpvMLduch3J6nsDvvZHX89H5Tp6/P6fWn54dM99u9vqef59XnV24/n0/eQIBMQIBMQIBMQIBMQIBMQIBMQIBMQIBMQIBMQIBMQIBMQIBMQIBMQIBMQIDsc3r+xNTb8zlOzyeZHp/anR/x0/NIpnbnf9y+PqfPP7U7P2W6fvX7vIEAmYAAmYAAmYAAmYAAmYAAmYAAmYAAmYAAmYAAmYAAmYAAmYAAmYAAmYAA2ef5D2/Pizi93+n5H7uffzq9/vS8jtO/9/Z8j9X6p9Pfd3r+qdvzRabX43k+byBAJiBAJiBAJiBAJiBAJiBAJiBAJiBAJiBAJiBAJiBAJiBAJiBAJiBAJiBA9m0eyNPpeRrT42+7Pf/ktNvzM26bPk+781t259389Hyc6fluPw/eQIBMQIBMQIBMQIBMQIBMQIBMQIBMQIBMQIBMQIBMQIBMQIBMQIBMQIBMQIDsM53H8LS7fneeyGq/0/M7Tn/f1f7TeRSr/Z5279/K7jyZt+exnH6ef3p+zOn/z8/j3kCATECATECATECATECATECATECATECATECATECATECATECATECATECATECA7DOd13B6vsTb8yim578932N6vt35Gqv9Vqbf//b93bX7/af3a+r083h6Pok3ECATECATECATECATECATECATECATECATECATECATECATECATECATECATECD7Nh7g9LyJ3XkJt+djvD2v4u3rcXr9dL+V2/NSnnafj+n5dt2+36v9VtfLGwiQCQiQCQiQCQiQCQiQCQiQCQiQCQiQCQiQCQiQCQiQCQiQCQiQCQiQCQiQ/QViOogIi4kH/wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=1088x128 at 0x24E1721E550>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize Predicted Output\n",
    "visualize(binary_output.permute(1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
